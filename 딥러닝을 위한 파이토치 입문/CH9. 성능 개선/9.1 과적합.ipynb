{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š ë°ì´í„° ì¦ì‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `transf`\n",
    "    - Datasetì„ ì •ì˜í•˜ê¸° ì „ì— ì •ì˜\n",
    "    - ë§ì€ ê¸°ëŠ¥ë“¤ì´ ì´ë¯¸ì§€ íƒ€ì…ì´ PILì¼ ê²½ìš° ì‘ë™í•˜ê¸° ë•Œë¬¸ì— ì‚¬ìš©ì „ì— ë°ì´í„° íƒ€ì…ì„ í™•ì¸í•´ì•¼ í•œë‹¤.\n",
    "- ê·¸ì™¸\n",
    "    - íšŒì „, í‘ë°± ì´ë¯¸ì§€ ë“±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as tr\n",
    "import PIL\n",
    "\n",
    "transf = tr.Compose([tr.ToPILImage(), \n",
    "                     tr.RandomCrop(60),\n",
    "                     # ì´ë¯¸ì§€ ë°ê¸°, ëŒ€ë¹„, ìƒ‰ì¡°ë¥¼ ë³€í˜•\n",
    "                     tr.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "                     # ì´ë¯¸ì§€ ë’¤ì§‘ê¸°\n",
    "                     tr.RandomHorizontalFlip(), \n",
    "                     tr.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š ì¡°ê¸° ì¢…ë£Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ’¡ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ’¡ í•™ìŠµ, ê²€ì¦, í‰ê°€ ë°ì´í„° ìƒì„±í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
    "\n",
    "trainset, valset = torch.utils.data.random_split(dataset, [30000, 20000])\n",
    "trainloader =  torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ’¡ GPU ì—°ì‚° í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 is available.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{device} is available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ’¡ ëª¨ë¸ ì •ì˜í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module) :\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1) :\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        # ì»¨ë³¼ë£¨ì…˜ ì—°ì‚° 2ê°œë¥¼ í¬í•¨í•œ ë¸”ë¡ ë§Œë“¤ê¸°\n",
    "            # Batch Normalization : ê° ë°°ì¹˜ì˜ í‰ê· ê³¼ ë¶„ì‚°ì„ ì´ìš©í•´ì„œ ë°ì´í„°ë¥¼ ì •ê·œí™”í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ í•™ìŠµì„ ë¹ ë¥´ê²Œ í•  ìˆ˜ ìˆë‹¤.\n",
    "        self.conv_block = nn.Sequential(nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "                                        nn.BatchNorm2d(self.out_channels),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                        nn.BatchNorm2d(self.out_channels))\n",
    "        \n",
    "        # ìœ„ì˜ ì„¤ëª… ì°¸ê³  (ì‚¬ì´ì¦ˆê°€ ë‹¬ë¼ì§€ê±°ë‚˜, ì±„ë„ì´ ë‹¬ë¼ì§€ë©´ ~ ì¡°ê±´ë¬¸ ì‹¤í–‰)\n",
    "        if self.stride != 1 or self.in_channels != self.out_channels :\n",
    "            self.downsample = nn.Sequential(nn.Conv2d(self.in_channels, self.out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                                            nn.BatchNorm2d(self.out_channels))\n",
    "            \n",
    "    def forward(self, x) :\n",
    "        out = self.conv_block(x)\n",
    "        \n",
    "        # ì‚¬ì´ì¦ˆ ì¡°ì •ì´ í•„ìš”í•˜ë‹¤ë©´ ì…ë ¥ê°’ì˜ í¬ê¸°ë¥¼ ì¡°ì •í•œë‹¤. \n",
    "        if self.stride != 1 or self.in_channels != self.out_channels :\n",
    "            x = self.downsample(x)\n",
    "            \n",
    "        # Skip connection\n",
    "        out = F.relu(x + out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "\n",
    "class ResNet(nn.Module) :\n",
    "    def __init__(self, num_blocks, num_classes=10) :\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        # ì…ë ¥ ì´ë¯¸ì§€ê°€ ë“¤ì–´ì™€ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” ê¸°ë³¸ì¸µ\n",
    "        self.base = nn.Sequential(nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                  nn.BatchNorm2d(64),\n",
    "                                  nn.ReLU())\n",
    "        \n",
    "        # ê¸°ë³¸ì¸µì„ ì œì™¸í•œ 4ê°œì˜ ë¸”ë¡ì´ í•„ìš”í•˜ë¯€ë¡œ, self._make_layerë¥¼ ì´ìš©í•˜ì—¬ 4ê°œì˜ ë¸”ë¡ ë¬¶ìŒì„ ì„ ì–¸í•œë‹¤. \n",
    "        self.layer1 = self._make_layer(64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(512, num_blocks[3], stride=2)\n",
    "        \n",
    "        # í•©ì„±ê³± ì¸µë“¤ì„ ì§€ë‚˜ë©´ ìµœì¢…ì ìœ¼ë¡œ í¬ê¸°ê°€ 4x4ì¸ feature map 512ê°œê°€ ë‚˜ì˜¨ë‹¤. \n",
    "        # í¬ê¸°ê°€ 4x4ì¸ í‰ê·  í’€ë§ì„ ì´ìš©í•˜ë©´ ê° í”¼ì³ë§µ ë‹¹ 1ê°œì˜ í‰ê· ê°’ì´ ë‚˜ì˜¤ê¸° ë•Œë¬¸ì— ì„±ë¶„ì´ 512ê°œì¸ ë²¡í„°ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.\n",
    "        self.gap = nn.AvgPool2d(4) # 4 is filter size\n",
    "        \n",
    "        # í´ë˜ìŠ¤ê°€ 10ê°œì¸ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” ê²ƒì´ë¯€ë¡œ ìµœì¢…ì ìœ¼ë¡œ 512ê°œì˜ ë…¸ë“œì—ì„œ 10ê°œì˜ ë…¸ë“œë¡œ ê°€ëŠ” FCë¥¼ ì •ì˜í•œë‹¤. \n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "        \n",
    "    def _make_layer(self, out_channels, num_blocks, stride) :\n",
    "        # ë¸”ë¡ì˜ ë°˜ë³µ íšŸìˆ˜ë§Œí¼ strideë¥¼ ì €ì¥\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        \n",
    "        # ResidualBlockì„ ë¶ˆëŸ¬ì™€ì„œ appendë¥¼ ì´ìš©í•´ ì°¨ë¡€ë¡œ ë¶™ì—¬ì¤€ë‹¤.\n",
    "        # ì´ë•Œ ì´ì „ ì¶œë ¥ ì±„ë„ í¬ê¸°ì™€ ë‹¤ìŒ ì…ë ¥ ì±„ë„ í¬ê¸°ê°€ ê°™ì•„ì•¼ í•œë‹¤. \n",
    "        layers = []\n",
    "        for stride in strides :\n",
    "            block = ResidualBlock(self.in_channels, out_channels, stride)\n",
    "            layers.append(block) \n",
    "            self.in_channels = out_channels\n",
    "            \n",
    "        # nn.Sequentialì— ë„£ì–´ ëª¨ë¸ì„ êµ¬ì¶•í•œë‹¤.\n",
    "        # *ë¦¬ìŠ¤íŠ¸ : ë¦¬ìŠ¤íŠ¸ì˜ ê¸¸ì´ì— ìƒê´€ ì—†ì´ ëª¨ë“  ì„±ë¶„ì„ ë³„ë„ë¡œ nn.Sequentialì— ì „ë‹¬í•˜ëŠ” ì—­í• ì„ í•œë‹¤. \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    \n",
    "    # ResNet í´ë˜ìŠ¤ ì•ˆì— ì—°ì‚°ì„ í–‰í•˜ëŠ” forward\n",
    "    def forward(self, x) :\n",
    "        out = self.base(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.gap(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜\n",
    "# ê° ëª¨ë¸ë§ˆë‹¤ ë¸”ë¡ì˜ ë°˜ë³µ íšŸìˆ˜ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜í•˜ì—¬ ì…ë ¥í•œë‹¤. \n",
    "# ì´ë¥¼ í†µí•´ 18, 34 ì™¸ì— 4ê°œì˜ ë¸”ë¡ì„ ê°€ì§„ ë ˆì´ì–´ì˜ ê°œìˆ˜ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆë‹¤. \n",
    "def modeltype(model) :\n",
    "    if model == 'resnet18' :\n",
    "        return ResNet([2, 2, 2, 2])\n",
    "    elif model == 'resnet34' :\n",
    "        return ResNet([3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = modeltype('resnet18').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
      "              ReLU-6           [-1, 64, 32, 32]               0\n",
      "            Conv2d-7           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-8           [-1, 64, 32, 32]             128\n",
      "     ResidualBlock-9           [-1, 64, 32, 32]               0\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "             ReLU-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-14           [-1, 64, 32, 32]             128\n",
      "    ResidualBlock-15           [-1, 64, 32, 32]               0\n",
      "           Conv2d-16          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-17          [-1, 128, 16, 16]             256\n",
      "             ReLU-18          [-1, 128, 16, 16]               0\n",
      "           Conv2d-19          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-20          [-1, 128, 16, 16]             256\n",
      "           Conv2d-21          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-22          [-1, 128, 16, 16]             256\n",
      "    ResidualBlock-23          [-1, 128, 16, 16]               0\n",
      "           Conv2d-24          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-25          [-1, 128, 16, 16]             256\n",
      "             ReLU-26          [-1, 128, 16, 16]               0\n",
      "           Conv2d-27          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-28          [-1, 128, 16, 16]             256\n",
      "    ResidualBlock-29          [-1, 128, 16, 16]               0\n",
      "           Conv2d-30            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-31            [-1, 256, 8, 8]             512\n",
      "             ReLU-32            [-1, 256, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "           Conv2d-35            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-36            [-1, 256, 8, 8]             512\n",
      "    ResidualBlock-37            [-1, 256, 8, 8]               0\n",
      "           Conv2d-38            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 8, 8]             512\n",
      "             ReLU-40            [-1, 256, 8, 8]               0\n",
      "           Conv2d-41            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-42            [-1, 256, 8, 8]             512\n",
      "    ResidualBlock-43            [-1, 256, 8, 8]               0\n",
      "           Conv2d-44            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-46            [-1, 512, 4, 4]               0\n",
      "           Conv2d-47            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-48            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-49            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-50            [-1, 512, 4, 4]           1,024\n",
      "    ResidualBlock-51            [-1, 512, 4, 4]               0\n",
      "           Conv2d-52            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-53            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-54            [-1, 512, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "    ResidualBlock-57            [-1, 512, 4, 4]               0\n",
      "        AvgPool2d-58            [-1, 512, 1, 1]               0\n",
      "           Linear-59                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,173,962\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 13.63\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 56.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì¶œë ¥\n",
    "torchsummary.summary(resnet, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ’¡ ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™” ê¸°ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_resnet_early.pth'\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ’¡ ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì†ì‹¤ í•¨ìˆ˜ê°’ì„ ì—°ì‚°í•˜ëŠ” í•¨ìˆ˜ ì •ì˜í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- í‰ê°€ë§Œ í•˜ê¸° ë•Œë¬¸ì— **requires_grad**ë¥¼ ë¹„í™œì„±í™”\n",
    "- í‰ê°€ ì‹œ **ì •ê·œí™” ê¸°ë²•**ë“¤ì´ ì‘ë™í•˜ì§€ ì•Šë„ë¡ eval ëª¨ë“œë¡œ ì„¤ì •\n",
    "- ë‹¤ì‹œ ëª¨ë¸ì„ train ëª¨ë“œë¡œ ë³€ê²½í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loss(dataloader) :\n",
    "    n = len(dataloader)\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad() :\n",
    "        resnet.eval()\n",
    "        for data in dataloader : \n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = resnet(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "    resnet.train()\n",
    "    return running_loss/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ’¡ í•™ìŠµí•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì†ì‹¤ í•¨ìˆ˜ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê¸° ìœ„í•´\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "# ë§¤ ì—í­ë§ˆë‹¤ í‰ê·  ì†ì‹¤í•¨ìˆ˜ê°’ì„ êµ¬í•˜ê¸° ìœ„í•´ n ì„¤ì •\n",
    "n = len(trainloader)\n",
    "\n",
    "# ê°€ì¥ ë‚®ì€ ê²€ì¦ ì†ì‹¤ í•¨ìˆ˜ê°’ì— í•´ë‹¹í•˜ëŠ” ëª¨ë¸ì„ ì €ì¥í•˜ê¸° ìœ„í•´ ì†ì‹¤ í•¨ìˆ˜ê°’ ì´ˆê¸° ê¸°ì¤€ì„ 1ë¡œ ì„¤ì •\n",
    "early_stopping_loss = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d48a4aa75719>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(5) :\n",
    "    running_loss = 0.0\n",
    "    for data in trainloader :\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    train_loss = running_loss / n\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss = validation_loss(valloader)\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('[%d] train loss : %.3f, validation loss : %.3f' % (epoch+1, train_loss, val_loss))\n",
    "    \n",
    "    if val_loss < early_stopping_loss :\n",
    "        torch.save(resnet.state_dict(), PATH)\n",
    "        ealry_stopping_train_loss = train_loss\n",
    "        early_stopping_val_loss = val_loss\n",
    "        early_stopping_epoch = epoch\n",
    "        \n",
    "print('Fianl pretrained model >> [%d] train loss : %.3f, validation loss : %.3f' % (early_stopping_epoch+1, early_stopping_train_loss, early_stopping_val_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ’¡ ì†ì‹¤ í•¨ìˆ˜ê°’ ê·¸ë¦¬ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list)\n",
    "plt.plot(val_loss_list)\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š L2 ì •ê·œí™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(resnet.parameters(), lr=1e-3, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(13, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = self.dropout(F.relu(self.fc(x)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š Batch ì •ê·œí™”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š êµë€ ë¼ë²¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ’¡ êµë€ë¼ë²¨ ì •ì˜í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisturbLabel(torch.nn.Module) :\n",
    "    def __init__(self, alpha, num_classes) :\n",
    "        super(DisturbLabel, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.C = num_classes\n",
    "        # ì‹¤ì œ ë¼ë²¨ì„ ë½‘ì„ í™•ë¥ \n",
    "        self.p_c = (1 - ((self.C-1)/self.C)*(alpha/100))\n",
    "        # ë‚˜ë¨¸ì§€\n",
    "        self.p_i = (1-self.p_c)/(self.C-1)\n",
    "        \n",
    "    def forward(self, y) :\n",
    "        # ì•ì„œ ì–¸ê¸‰í•œ ë¼ë²¨ì´ ë½‘í í™•ë¥  ë¶„í¬ (3/100, 3/100, 3/100, 3/100, 3/100, 73/100, 3/100, 3/100, 3/100, 3/100)ì„ ë§Œë“¤ì–´ì¤€ë‹¤. \n",
    "        y_tensor = y.type(torch.LongTensor).view(-1, 1)\n",
    "        depth = self.C\n",
    "        y_one_hot = torch.ones(y_tensor.size()[0], depth) * self.p_i\n",
    "        y_one_hot.scatter_(1, y_tensor, self.p_c)\n",
    "        \n",
    "        # í•´ë‹¹ í™•ë¥ ì„ ì´ìš©í•´ Multinoulli ë¶„í¬ë¥¼ í†µí•´ ìƒ˜í”Œì„ ë½‘ëŠ”ë‹¤.\n",
    "        y_one_hot = y_one_hot.view(*(tuple(y.shape) + (-1,)))\n",
    "        distribution = torch.distributions.OneHoetCategorical(y_one_hot)\n",
    "        y_disturbed = distribution.sample()\n",
    "        \n",
    "        # 10ê°œì˜ ì›ì†Œ ì¤‘ ê°€ì¥ í° ê°’ì˜ ë¼ë²¨ì„ ë½‘ëŠ”ë‹¤.\n",
    "        y_disturbed = y_disturbed.max(dim=1)[1]\n",
    "        return y_disturbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ’¡ êµë€ë¼ë²¨ ì„ ì–¸ ë° ì ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "disturblabels = DisturbLabel(alpha=30, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(50) :\n",
    "    running_loss = 0.0\n",
    "    for data in trainloader :\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet(inputs)\n",
    "        labels = disturblabels(labels).to(device)\n",
    "        loss = criterion(outputs, labels)\n",
    "        ...ì´í•˜ ìƒëµ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š êµë€ê°’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ’¡ ë…¸ì´ì¦ˆ ìƒì„±í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target ê°’ê³¼ noise ë¹„ìœ¨ì„ ë°›ëŠ”ë‹¤.\n",
    "def noise_generator(x, alpha) :\n",
    "    # ì„ì˜ë¡œ ì •í•œ ì •ê·œë¶„í¬ì— ë”°ë¥¸ ë…¸ì´ì¦ˆ ìƒì„±\n",
    "    noise = torch.normal(0, 1e-8, size=(len(x), 1))\n",
    "    # ë…¸ì´ì¦ˆ íƒ€ê¹ƒì´ ì•„ë‹Œ ê°’ì€ ë…¸ì´ì¦ˆë¥¼ 0ìœ¼ë¡œ í•œë‹¤. \n",
    "    noise[torch.randint(0, len(x), (int(len(x)*(1-alpha)),))] = 0\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ’¡ êµë€ê°’ ì„ ì–¸ ë° ì ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(400) :\n",
    "    for data in trainloader :\n",
    "        inputs, values = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        values = values + noise_generator(values, alpha)\n",
    "        loss = criterion(outputs, values)\n",
    "        ...ì´í•˜ ìƒëµ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š ë¼ë²¨ ìŠ¤ë¬´ë”©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ’¡ ë¼ë²¨ ìŠ¤ë¬´ë”© ì •ì˜ ë° ì„ ì–¸í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module) : \n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1) :\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "        \n",
    "    def forward(self, pred, target) :\n",
    "        # cross-entropy ë¶€ë¶„ì˜ log softmaxë¥¼ ë¯¸ë¦¬ ê³„ì‚°í•œë‹¤. \n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad() : \n",
    "            # ì˜ˆì¸¡ê°’ê³¼ ë™ì¼í•œ í¬ê¸°ì˜ ì˜í…ì„œ ë§Œë“¤ê¸°\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls-1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        # ìœ„ì—ì„œ ë§Œë“  predë¥¼ í•¨ê»˜ ì‚¬ìš©í•´ cross entropy loss í•¨ìˆ˜ë¥¼ ê³„ì‚°\n",
    "        return torch.mean(torch.sum(-true_dis * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.CrossEntropyLoss() ëŒ€ì‹ , LabelSmoothingLossë¡œ criterion ì„ ì–¸\n",
    "criterion = LabelSmoothingLoss(classes=10, smoothing=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
