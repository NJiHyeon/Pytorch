{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📚 사전 학습 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torchvision.models as models`를 이용해 ImageNet 데이터로 학습된 사전 학습 모델 (pretrained model) 사용 가능\n",
    "- 또한 모델 내부의 변수명을 확인하고 모델 일부 수정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.8/site-packages/torchvision/models/inception.py:75: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn('The default weight initialization of inception_v3 will be changed in future releases of '\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "alexnet = models.alexnet().to(device)\n",
    "resnet18 = models.resnet18().to(device)\n",
    "vgg16 = models.vgg16().to(device)\n",
    "densenet = models.densenet161().to(device)\n",
    "inception = models.inception_v3().to(device)\n",
    "googlenet = models.googlenet().to(device)\n",
    "shufflenet = models.shufflenet_v2_x1_0().to(device)\n",
    "mobilenet_v2 = models.mobilenet_v2().to(device)\n",
    "resnext50_32x4d = models.resnext50_32x4d().to(device)\n",
    "wide_resnet50_2 = models.wide_resnet50_2().to(device)\n",
    "mnasnet = models.mnasnet1_0().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 💡 CIFAR10을 위한 ResNet18 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 무조건 바꿔야 할 것 : 맨 처음(필터 사이즈)와 맨 끝(출력 사이즈)\n",
    "- 중간중간에는 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "# 필터 사이즈 7x7 -> 3x3\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "# 마지막 출력 노드가 1000이기 때문에 데이터에 맞춰 10으로 변경\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📚 모델 프리징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **기존의 일부 모델 변수들을 그대로 사용하기 위해 업데이트가 되지 않도록** 하는 방법\n",
    "- 사전 학습된 변수를 그대로 유지하기 때문에 학습 속도와 정확도를 향상시킬 수 있고, 다른 모델과 붙여 다른 구조를 만들 수 있다.\n",
    "    - ex) CNN에서 feature extraction 부분은 freezing을 시키고, classification 부분만 학습을 하기도 하는데, model tuning/freezing은 정답이 없으므로 다양한 시도가 중요하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 💡 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 불러온 후, output layer의 노드를 클래스 수와 맞춘다. \n",
    "model = torchvision.models.alexnet(pretrained=True)\n",
    "num_ftrs = model.classifier[6].in_features # 4096\n",
    "model.classifier[6] = nn.Linear(num_ftrs,10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4096, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 💡 모델 파라미터명 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 features.0.weight\n",
      "1 features.0.bias\n",
      "2 features.3.weight\n",
      "3 features.3.bias\n",
      "4 features.6.weight\n",
      "5 features.6.bias\n",
      "6 features.8.weight\n",
      "7 features.8.bias\n",
      "8 features.10.weight\n",
      "9 features.10.bias\n",
      "10 classifier.1.weight\n",
      "11 classifier.1.bias\n",
      "12 classifier.4.weight\n",
      "13 classifier.4.bias\n",
      "14 classifier.6.weight\n",
      "15 classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "for i, (name, param) in enumerate(model.named_parameters()) :\n",
    "    print(i, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 💡 변수 프리징하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "# requires_grad를 False로 하여 학습 시 업데이트가 되지 않게 한다.\n",
    "for i, (name, param) in enumerate(model.named_parameters()) :\n",
    "    param.requires_grad = False\n",
    "    # 합성곱 층에 대한 가중치와 편향(9번까지만)만 프리징 되면 for문을 멈춘다.\n",
    "    if i == 9 :\n",
    "        print('end')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 💡 Requires_grad 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "f_list = [0, 3, 6, 8, 10]\n",
    "c_list = [1, 4, 6]\n",
    "for i in f_list :\n",
    "    print(model.features[i].weight.requires_grad)\n",
    "    print(model.features[i].bias.requires_grad)\n",
    "    \n",
    "for j in c_list : \n",
    "    print(model.classifier[j].weight.requires_grad)\n",
    "    print(model.classifier[j].bias.requires_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
