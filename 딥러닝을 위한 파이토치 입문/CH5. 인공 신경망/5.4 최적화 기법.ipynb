{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760f6477-7959-49df-b591-9d716bfb98fd",
   "metadata": {},
   "source": [
    "#### 5.4.1 🔎 확률적 경사하강법(SGD) - torch.optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c79bd5-131d-4f26-97c0-47b2c2bee877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc5deb4-6476-4f0e-9a48-f6448304cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b34753-edaf-4fd3-8a06-89ea7cd712fc",
   "metadata": {},
   "source": [
    "#### 5.4.2 🔎 다양한 최적화 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb27e88-c7de-4c48-89da-de4aa9e315a9",
   "metadata": {},
   "source": [
    "##### 💡 momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47415a3-1b22-457d-b9ad-b2fcfa6faf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530b4ce8-cb27-4bf7-950b-8bcaaee8d578",
   "metadata": {},
   "source": [
    "##### 💡 Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5b035b-0fb7-4c37-a781-f8596a51b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca9ee57-777e-4e6a-a5ff-36d328cedaf7",
   "metadata": {},
   "source": [
    "##### 💡 기타"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cf201f-398c-4477-9ebb-adcfe08307ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.Adadelta\n",
    "torch.optim.Adagrad\n",
    "torch.optim.RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f5f18a-9b7c-47dd-a94e-6a57b1972b3e",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe400fd-a709-4340-b8ba-bd84f3cb893b",
   "metadata": {},
   "source": [
    "#### 5.4.3 🔎 스케줄링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fab024-c5b2-4a8b-b803-bbeb38c32094",
   "metadata": {},
   "source": [
    "- 가변 학습률을 사용하지 않는 방법 (Momentum, Nesterov, Nadam 등)에 대해서는 학습률이 변하지 않는다.\n",
    "- 스케줄링 : 별도로 학습률이 어떻게 바뀌는지 규칙을 정해주는 것\n",
    "    - `optim.lr_scheduler.StepLR`에서 `gamma=감소시킬 학습률`으로 가능\n",
    "    - for문 안에 `scheduler.step()`추가하면 자동으로 학습률 변경해준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ec14ac-6476-402d-b22b-6c6275dc2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "...중략...\n",
    "for epoch in range(400) :\n",
    "    running_loss = 0.0\n",
    "    for data in dataloader :\n",
    "        inputs, values = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, values)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ...중략...\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b510ae7-68e6-4ee4-b177-10d3e47d594a",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08bd2f3-a25a-4adc-86d9-6e4568c39dde",
   "metadata": {},
   "source": [
    "#### 5.4.4 🔎 MADGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d6786a-d340-4108-a823-9555f25665ad",
   "metadata": {},
   "source": [
    "- 모멘텀과 가변식 방법 병행하는 최신 최적화 방법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2c2d86-1ca7-472a-aecb-62d9e53a11a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "madgrad.MADGRAD(모델 변수, lr = 학습률(default:0.01), \n",
    "                momentum = 모멘텀지수(default=0.9), \n",
    "                weight_decay = L2페널티(defual:0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec123eaa-46d9-4e5f-8d71-88646b38209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting madgrad\n",
      "  Downloading madgrad-1.2-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: madgrad\n",
      "Successfully installed madgrad-1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install madgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc1c27-ad04-4a8a-a76f-dfac7b554c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import padgrad\n",
    "optimizer = madgrad.MADGRAD(model.parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
