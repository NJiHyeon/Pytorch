{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📚 Bi-LSTM 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 💡 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 💡 MNIST 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 숫자 이미지 판별을 양방향 LSTM을 통해 예측\n",
    "- 이미지는 주로 **(배치사이즈, 채널수, 이미지 너비, 이미지 높이)** 형태의 크기를 지니고 있다.\n",
    "    - MNIST 데이터의 채널 수는 1이고, 이미지 크기가 28x28이므로 각 배치 데이터의 크기는 **(배치사이즈, 1, 28, 28)**\n",
    "    - 이때 크기를 (배치사이즈, 28, 28)로 생각할 수 있다.\n",
    "    - 이미지 픽셀의 각 열을 하나의 벡터로 보고, 행을 타임 스텝으로 본다면 **(배치 사이즈, 시계열의 길이, 벡터의 크기)**를 가진 시계열 데이터로 생각할 수 있다.\n",
    "- 즉, 순환 신경망(RNN)도 이미지 처리에 활용될 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_mode = torchvision.transforms.ToTensor()\n",
    "trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform = tensor_mode, download=True)\n",
    "testset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform = tensor_mode, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 💡 Bi-LSTM 모델 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module) :\n",
    "    def __init__(self, input_size, hidden_size, num_layers, seq_length, num_classes, device) :\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_length = seq_length\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True, bidirectional = True) \n",
    "        self.fc = nn.Linear(seq_length*hidden_size*2, num_classes)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out.reshape(-1, self.seq_length*self.hidden_size*2)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `init` 함수에서\n",
    "    - 입력값의 크기(이미지의 열 크기), 은닉층의 노드수, 은닉층의 개수, 시계열의 길이(이미지의 행 크기), 클래스 수, gpu 활용 여부\n",
    "- `lstm`\n",
    "    - bidirectional = True : 양방향 LSTM을 생성\n",
    "    - batch_first = True : 크기가 (배치 사이즈, 시계열의 길이, 입력값의 크기)를 지닌 데이터\n",
    "- `fc` \n",
    "    - 모든 타임 스텝에 대한 LSTM 결과를 분류에 사용한다. \n",
    "    - 입력값의 크기는 **시계열의 길이 * 은닉층의 크기 * 2**\n",
    "    - 양방향 LSTM은 정방향, 역방향에 대한 LSTM을 계산한 후 합칠 결과 (concatenate)를 사용\n",
    "    - 따라서 각각의 은닉층 결과 2개가 합쳐지므로 2를 곱한다.\n",
    "- `h0, c0`\n",
    "    - 은닉 상태와 셀 상태의 초깃값을 정의한다. \n",
    "    - 여기서도 양방향에 대한 초깃값을 지정해야 하므로 은닉층의 개수에 2를 곱한다. \n",
    "- `out`\n",
    "    - 모델에서 나온 out의 크기는 **(배치사이즈, 시계열의 길이, 은닉층의 노드수 * 2)**\n",
    "    - 모든 데이터를 nn.Linear에 사용하기 위해 reshape하여 **(배치사이즈, 시계열의 길이 * 은닉층의 노드수 * 2)**로 변경\n",
    "    - fc를 태워서 크기가 10(클래스 수)인 출력 벡터를 산출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 💡 하이퍼 파라미터 정의하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델에 필요한 변수 정의\n",
    "- 이미지 데이터의 행 : 시계열\n",
    "- 이미지 데이터의 열 : 입력 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 이미지 데이터의 행 : 시계열\n",
    "sequence_length = trainset.data.size(1)\n",
    "# 이미지 데이터의 열 : 입력 벡터\n",
    "input_size = trainset.data.size(2)\n",
    "\n",
    "num_layers = 2\n",
    "hidden_size = 12\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 💡 모델, 손실함수, 최적화 기법 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(input_size, hidden_size, num_layers, sequence_length, num_classes, device)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 💡 모델 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원래 배치 데이터의 크기가 **(배치사이즈, 1, 28, 28)**이므로 `squeeze(1)`을 통해서 데이터의 크기를 **(배치사이즈, 28, 28)**로 변환\n",
    "- 학습 도중 정확도를 구할 때에는 변수 업데이트가 필요 없으므로 `detach()`를 사용하여 outputs의 `requires_grad`를 비활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] train acc: 91.92\n",
      "[1] train acc: 97.72\n",
      "[2] train acc: 98.28\n",
      "[3] train acc: 98.59\n",
      "[4] train acc: 98.83\n",
      "[5] train acc: 98.91\n",
      "[6] train acc: 99.06\n",
      "[7] train acc: 99.13\n",
      "[8] train acc: 99.12\n",
      "[9] train acc: 99.31\n",
      "[10] train acc: 99.32\n",
      "[11] train acc: 99.32\n",
      "[12] train acc: 99.35\n",
      "[13] train acc: 99.48\n",
      "[14] train acc: 99.42\n",
      "[15] train acc: 99.54\n",
      "[16] train acc: 99.52\n",
      "[17] train acc: 99.62\n",
      "[18] train acc: 99.60\n",
      "[19] train acc: 99.59\n",
      "[20] train acc: 99.62\n",
      "[21] train acc: 99.61\n",
      "[22] train acc: 99.64\n",
      "[23] train acc: 99.62\n",
      "[24] train acc: 99.65\n",
      "[25] train acc: 99.65\n",
      "[26] train acc: 99.68\n",
      "[27] train acc: 99.79\n",
      "[28] train acc: 99.72\n",
      "[29] train acc: 99.65\n",
      "[30] train acc: 99.66\n",
      "[31] train acc: 99.73\n",
      "[32] train acc: 99.83\n",
      "[33] train acc: 99.74\n",
      "[34] train acc: 99.66\n",
      "[35] train acc: 99.78\n",
      "[36] train acc: 99.78\n",
      "[37] train acc: 99.75\n",
      "[38] train acc: 99.74\n",
      "[39] train acc: 99.89\n",
      "[40] train acc: 99.73\n",
      "[41] train acc: 99.65\n",
      "[42] train acc: 99.81\n",
      "[43] train acc: 99.80\n",
      "[44] train acc: 99.82\n",
      "[45] train acc: 99.80\n",
      "[46] train acc: 99.84\n",
      "[47] train acc: 99.82\n",
      "[48] train acc: 99.68\n",
      "[49] train acc: 99.77\n",
      "[50] train acc: 99.94\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(51) :\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in trainloader :\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = data[0].to(device).squeeze(1), data[1].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs.detach(), 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "    print(\"[%d] train acc: %.2f\" %(epoch, 100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 💡 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(dataloader) :\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad() :\n",
    "        model.eval()\n",
    "        for data in dataloader :\n",
    "            inputs, labels = data[0].to(device).squeeze(1), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted==labels).sum().item()\n",
    "    acc = 100*correct/total\n",
    "    model.train()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ACC : 100.0, Test ACC : 98.6\n"
     ]
    }
   ],
   "source": [
    "train_acc = accuracy(trainloader)\n",
    "test_acc = accuracy(testloader)\n",
    "print(\"Train ACC : %.1f, Test ACC : %.1f\" %(train_acc, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
