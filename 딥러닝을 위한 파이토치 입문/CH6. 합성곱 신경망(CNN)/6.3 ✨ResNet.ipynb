{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 💡 Residual block 구축하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ResNet은 ResidualBlock 하나를 거칠 때마다 이미지 사이즈가 줄어들고, 채널 수는 늘어나는 구조\n",
    "- 따라서 처음 들어오는 x값과 블록을 거친 출력값 out의 크기가 같아야만 한다. \n",
    "- 따라서 차이가 나는 경우 출력값의 크기와 입력값의 크기를 동일하게 하기 위해 별도의 컨볼루션 연산을 수행하여 입력 크기를 출력 크기와 맞춰준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module) :\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1) :\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        # 컨볼루션 연산 2개를 포함한 블록 만들기\n",
    "            # Batch Normalization : 각 배치의 평균과 분산을 이용해서 데이터를 정규화하는 방법으로 학습을 빠르게 할 수 있다.\n",
    "        self.conv_block = nn.Sequential(nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "                                        nn.BatchNorm2d(self.out_channels),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                        nn.BatchNorm2d(self.out_channels))\n",
    "        \n",
    "        # 위의 설명 참고 (사이즈가 달라지거나, 채널이 달라지면 ~ 조건문 실행)\n",
    "        if self.stride != 1 or self.in_channels != self.out_channels :\n",
    "            self.downsample = nn.Sequential(nn.Conv2d(self.in_channels, self.out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                                            nn.BatchNorm2d(self.out_channels))\n",
    "            \n",
    "    def forward(self, x) :\n",
    "        out = self.conv_block(x)\n",
    "        \n",
    "        # 사이즈 조정이 필요하다면 입력값의 크기를 조정한다. \n",
    "        if self.stride != 1 or self.in_channels != self.out_channels :\n",
    "            x = self.downsample(x)\n",
    "            \n",
    "        # Skip connection\n",
    "        out = F.relu(x + out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 💡 ResNet 모델 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module) :\n",
    "    def __init__(self, num_blocks, num_classes=10) :\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        # 입력 이미지가 들어와 연산을 수행하는 기본층\n",
    "        self.base = nn.Sequential(nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                  nn.BatchNorm2d(64),\n",
    "                                  nn.ReLU())\n",
    "        \n",
    "        # 기본층을 제외한 4개의 블록이 필요하므로, self._make_layer를 이용하여 4개의 블록 묶음을 선언한다. \n",
    "        self.layer1 = self._make_layer(64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(512, num_blocks[3], stride=2)\n",
    "        \n",
    "        # 합성곱 층들을 지나면 최종적으로 크기가 4x4인 feature map 512개가 나온다. \n",
    "        # 크기가 4x4인 평균 풀링을 이용하면 각 피쳐맵 당 1개의 평균값이 나오기 때문에 성분이 512개인 벡터를 얻을 수 있다.\n",
    "        self.gap = nn.AvgPool2d(4) # 4 is filter size\n",
    "        \n",
    "        # 클래스가 10개인 이미지를 분류하는 것이므로 최종적으로 512개의 노드에서 10개의 노드로 가는 FC를 정의한다. \n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "        \n",
    "    def _make_layer(self, out_channels, num_blocks, stride) :\n",
    "        # 블록의 반복 횟수만큼 stride를 저장\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        \n",
    "        # ResidualBlock을 불러와서 append를 이용해 차례로 붙여준다.\n",
    "        # 이때 이전 출력 채널 크기와 다음 입력 채널 크기가 같아야 한다. \n",
    "        layers = []\n",
    "        for stride in strides :\n",
    "            block = ResidualBlock(self.in_channels, out_channels, stride)\n",
    "            layers.append(block) \n",
    "            self.in_channels = out_channels\n",
    "            \n",
    "        # nn.Sequential에 넣어 모델을 구축한다.\n",
    "        # *리스트 : 리스트의 길이에 상관 없이 모든 성분을 별도로 nn.Sequential에 전달하는 역할을 한다. \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    \n",
    "    # ResNet 클래스 안에 연산을 행하는 forward\n",
    "    def forward(self, x) :\n",
    "        out = self.base(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.gap(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스를 불러오는 함수\n",
    "# 각 모델마다 블록의 반복 횟수를 리스트로 정의하여 입력한다. \n",
    "# 이를 통해 18, 34 외에 4개의 블록을 가진 레이어의 개수를 조정할 수 있다. \n",
    "def modeltype(model) :\n",
    "    if model == 'resnet18' :\n",
    "        return ResNet([2, 2, 2, 2])\n",
    "    elif model == 'resnet34' :\n",
    "        return ResNet([3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 💡 ResNet18 학습 및 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AlexNet 평가에서 사용한 코드로 학습과 평가 과정 동일하게 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 📚 전체적으로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 데이터 세트 불러오기\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ad17ea1b634a51a915a2368977463b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 is available\n"
     ]
    }
   ],
   "source": [
    "# GPU 연산 체크\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{device} is available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (base): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (gap): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 선언\n",
    "model = modeltype('resnet18').to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
      "              ReLU-6           [-1, 64, 32, 32]               0\n",
      "            Conv2d-7           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-8           [-1, 64, 32, 32]             128\n",
      "     ResidualBlock-9           [-1, 64, 32, 32]               0\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "             ReLU-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-14           [-1, 64, 32, 32]             128\n",
      "    ResidualBlock-15           [-1, 64, 32, 32]               0\n",
      "           Conv2d-16          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-17          [-1, 128, 16, 16]             256\n",
      "             ReLU-18          [-1, 128, 16, 16]               0\n",
      "           Conv2d-19          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-20          [-1, 128, 16, 16]             256\n",
      "           Conv2d-21          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-22          [-1, 128, 16, 16]             256\n",
      "    ResidualBlock-23          [-1, 128, 16, 16]               0\n",
      "           Conv2d-24          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-25          [-1, 128, 16, 16]             256\n",
      "             ReLU-26          [-1, 128, 16, 16]               0\n",
      "           Conv2d-27          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-28          [-1, 128, 16, 16]             256\n",
      "    ResidualBlock-29          [-1, 128, 16, 16]               0\n",
      "           Conv2d-30            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-31            [-1, 256, 8, 8]             512\n",
      "             ReLU-32            [-1, 256, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "           Conv2d-35            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-36            [-1, 256, 8, 8]             512\n",
      "    ResidualBlock-37            [-1, 256, 8, 8]               0\n",
      "           Conv2d-38            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 8, 8]             512\n",
      "             ReLU-40            [-1, 256, 8, 8]               0\n",
      "           Conv2d-41            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-42            [-1, 256, 8, 8]             512\n",
      "    ResidualBlock-43            [-1, 256, 8, 8]               0\n",
      "           Conv2d-44            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-46            [-1, 512, 4, 4]               0\n",
      "           Conv2d-47            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-48            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-49            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-50            [-1, 512, 4, 4]           1,024\n",
      "    ResidualBlock-51            [-1, 512, 4, 4]               0\n",
      "           Conv2d-52            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-53            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-54            [-1, 512, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "    ResidualBlock-57            [-1, 512, 4, 4]               0\n",
      "        AvgPool2d-58            [-1, 512, 1, 1]               0\n",
      "           Linear-59                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,173,962\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 13.63\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 56.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 모델 출력\n",
    "torchsummary.summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 및 최적화 방법 정의하기\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "resnet = modeltype('resnet18').to(device)\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 1.330\n",
      "[2] loss: 0.831\n",
      "[3] loss: 0.619\n",
      "[4] loss: 0.481\n",
      "[5] loss: 0.377\n",
      "[6] loss: 0.277\n",
      "[7] loss: 0.195\n",
      "[8] loss: 0.140\n",
      "[9] loss: 0.103\n",
      "[10] loss: 0.086\n",
      "[11] loss: 0.068\n",
      "[12] loss: 0.066\n",
      "[13] loss: 0.053\n",
      "[14] loss: 0.049\n",
      "[15] loss: 0.041\n",
      "[16] loss: 0.043\n",
      "[17] loss: 0.036\n",
      "[18] loss: 0.036\n",
      "[19] loss: 0.034\n",
      "[20] loss: 0.031\n",
      "[21] loss: 0.029\n",
      "[22] loss: 0.027\n",
      "[23] loss: 0.028\n",
      "[24] loss: 0.025\n",
      "[25] loss: 0.022\n",
      "[26] loss: 0.022\n",
      "[27] loss: 0.021\n",
      "[28] loss: 0.021\n",
      "[29] loss: 0.021\n",
      "[30] loss: 0.019\n",
      "[31] loss: 0.019\n",
      "[32] loss: 0.018\n",
      "[33] loss: 0.016\n",
      "[34] loss: 0.016\n",
      "[35] loss: 0.018\n",
      "[36] loss: 0.016\n",
      "[37] loss: 0.014\n",
      "[38] loss: 0.016\n",
      "[39] loss: 0.014\n",
      "[40] loss: 0.015\n",
      "[41] loss: 0.010\n",
      "[42] loss: 0.013\n",
      "[43] loss: 0.013\n",
      "[44] loss: 0.012\n",
      "[45] loss: 0.010\n",
      "[46] loss: 0.015\n",
      "[47] loss: 0.010\n",
      "[48] loss: 0.011\n",
      "[49] loss: 0.010\n",
      "[50] loss: 0.013\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습하기\n",
    "\n",
    "# 그래프를 그리기 위한 loss 저장용 리스트\n",
    "loss_ = []\n",
    "\n",
    "# 배치개수\n",
    "n = len(trainloader)\n",
    "\n",
    "for epoch in range(50) :\n",
    "    running_loss = 0.0\n",
    "    for data in trainloader :\n",
    "        # 원래는 inputs, labels = data로 하는데 각각 device 붙여주기 위해 인덱스로 따로 뗌\n",
    "        # 배치 데이터\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 예측값 산출\n",
    "        outputs = resnet(inputs)\n",
    "        \n",
    "        # 손실함수 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 손실 함수 기준으로 역전파 선언\n",
    "        loss.backward()\n",
    "        \n",
    "        # 가중치 최적화\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    loss_.append(running_loss/n)\n",
    "    print('[%d] loss: %.3f' % (epoch+1, running_loss/len(trainloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 손실 함수 그래프 그리기\n",
    "plt.plot(loss_)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 경로와 모델평.pth 입력 (폴더는 만들어주어야 함)\n",
    "PATH = './model/cifal_resnet.pth'\n",
    "# 모델 저장\n",
    "torch.save(resnet.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 84.77 %\n"
     ]
    }
   ],
   "source": [
    "# 평가하기\n",
    "\n",
    "# 정답 개수\n",
    "correct = 0\n",
    "\n",
    "# 전체 개수\n",
    "total = 0\n",
    "\n",
    "# 평가 시에는 requires_grad 비활성화\n",
    "with torch.no_grad() :\n",
    "    # 평가 시에는 드롭아웃 등과 같은 정규화 작업 X (비활성화)\n",
    "    resnet.eval()\n",
    "    for data in testloader :\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = resnet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print('Test accuracy: %.2f %%' %(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✨ 평가 결과, AlexNet 보다 정확도가 높게 나왔다 !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
