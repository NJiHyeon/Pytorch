{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30b960a6-656b-4705-b741-7ae9bb4846d0",
   "metadata": {},
   "source": [
    "##### 💡 **라이브러리 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "622f3326-eeec-4401-bfd5-fc102a20b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c74e6212-dcda-427a-b3c2-f944fa0bed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4803bd-6716-4f72-9ed3-c7da718d0e86",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda5c13c-de47-415e-b506-c4df78664055",
   "metadata": {},
   "source": [
    "##### 💡 **CIFAR10 데이터 세트 불러오기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd85c999-61c5-453f-8d48-2f4db70bd6e5",
   "metadata": {},
   "source": [
    "- transforms.Normalize \n",
    "    - 특정 평균과 표준편차를 따르는 정규분포를 통해 이미지를 표준화하는 방법\n",
    "    - CIFAR 10은 3채널 컬러 이미지이므로 각 장의 평균과 표준편차를 정한다. \n",
    "    - 첫번째 (0.5, 0.5, 0.5) : 각 채널 당 평균을 할당한 것 (튜플로 입력)\n",
    "    - 두번째 (0.5, 0.5, 0.5) : 각 채널 당 표준편차를 기입\n",
    "    - 평균과 표준편차는 학습 전에 가지고 있는 이미지로부터 계산하지만 일단 임의의 값 0.5로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06205709-654a-4ec1-afdc-b4b1e35e5354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ad09a-799b-4a4b-b183-1c7cc0ed9ba0",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18ac34-f304-4c77-bffa-73ad6f9b266c",
   "metadata": {},
   "source": [
    "##### 💡 **GPU 연산 체크하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25c3eee-9721-482f-9717-b1884fd15c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 is available\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{device} is available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f511f-f30e-4534-a914-6df256c4a56a",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d22913-2e74-43d3-855d-5f9e73aa82b1",
   "metadata": {},
   "source": [
    "##### 💡 **AlexNet 구축하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb25eb4-eb33-4dc8-9042-611c97ad1524",
   "metadata": {},
   "source": [
    "- AlexNet은 ImageNet 데이터를 위해 만들어졌다.\n",
    "- ImageNet\n",
    "    - 1000개의 클래스로 분류되어있는 256x256 또는 224x224 크기를 갖는 이미지\n",
    "    - 크기가 32x32인 CIFAR10의 이미지는 제대로 동작을 안 할 수 있다.\n",
    "    - 따라서 **데이터에 맞게 필터의 크기와 보폭 수를 조정해 모델을 구축**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc2977e-5030-4aa6-8f2a-ce7fc888a2ec",
   "metadata": {},
   "source": [
    "- `self.features` : 합성곱 연산과 풀링 연산이 행해지는 피쳐추출(**Feature extraction**) 부분\n",
    "    - `nn.Sequential`\n",
    "        - 순차적으로 행해지는 연산을 한번에 묶을 수 있다. \n",
    "        - 괄호 안에는 작성 순서대로 연산이 수행\n",
    "    - `nn.Conv2d(입력 채널 수, 출력 채널 수, 필터의 크기)`\n",
    "        - 제일 첫번째 입력 채널 수는 RGB 컬러 이미지의 경우 3(그 후에는 이전 층의 출력값 = 다음 층의 입력값의 크기)\n",
    "        - 출력 채널 수는 임의의 값\n",
    "        - `padding` : 해당 층의 입력 피쳐맵의 가장 외곽을 0으로 한 겹 둘러싼다는 의미\n",
    "        (padding_mode에는 zeros, reflect, replicate, circular)\n",
    "        - `stride`\n",
    "    - `nn.MaxPool2d(필터의 크기, 보폭)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d7e71-c032-4131-a093-03d3d3d4e69d",
   "metadata": {},
   "source": [
    "- `self.classifier` : Fully-connected layer(FC)로 구성\n",
    "    - 처음 들어오는 입력값의 크기 = self.features에서 나온 피쳐맵을 일렬로 편 벡터의 크기\n",
    "    - CIFAR10은 10개의 클래스를 가진 데이터이므로 마지막 노드 수는 10\n",
    "    - 나머지 노드 수, 드롭아웃은 임의 지정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8e5aa3-722a-414d-a59c-a648d1c88821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(nn.Conv2d(3, 64, 3), nn.ReLU(),\n",
    "                                      nn.MaxPool2d(2, 2),\n",
    "                                      nn.Conv2d(64, 192, 3, padding=1), nn.ReLU(),\n",
    "                                      nn.MaxPool2d(2, 2),\n",
    "                                      nn.Conv2d(192, 384, 3, padding=1), nn.ReLU(),\n",
    "                                      nn.Conv2d(384, 256, 3, padding=1), nn.ReLU(),\n",
    "                                      nn.Conv2d(256, 256, 1), nn.ReLU(),\n",
    "                                      nn.MaxPool2d(2, 2))\n",
    "                                      \n",
    "            \n",
    "        self.classifier = nn.Sequential(nn.Dropout(0.5),\n",
    "                                        nn.Linear(256*3*3, 1024), nn.ReLU(),\n",
    "                                        nn.Dropout(0.5),\n",
    "                                        nn.Linear(1024, 512), nn.ReLU(),\n",
    "                                        nn.Linear(512, 10))\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, 256*3*3)\n",
    "        print(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e7c8fc8-5f5e-4605-8f6d-19853198a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ca33a7e-475e-44ae-8f39-ba39e8e55bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0614, 0.0603, 0.0633,  ..., 0.0712, 0.0528, 0.0554],\n",
      "        [0.0605, 0.0584, 0.0612,  ..., 0.0676, 0.0531, 0.0583]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 30, 30]           1,792\n",
      "              ReLU-2           [-1, 64, 30, 30]               0\n",
      "         MaxPool2d-3           [-1, 64, 15, 15]               0\n",
      "            Conv2d-4          [-1, 192, 15, 15]         110,784\n",
      "              ReLU-5          [-1, 192, 15, 15]               0\n",
      "         MaxPool2d-6            [-1, 192, 7, 7]               0\n",
      "            Conv2d-7            [-1, 384, 7, 7]         663,936\n",
      "              ReLU-8            [-1, 384, 7, 7]               0\n",
      "            Conv2d-9            [-1, 256, 7, 7]         884,992\n",
      "             ReLU-10            [-1, 256, 7, 7]               0\n",
      "           Conv2d-11            [-1, 256, 7, 7]          65,792\n",
      "             ReLU-12            [-1, 256, 7, 7]               0\n",
      "        MaxPool2d-13            [-1, 256, 3, 3]               0\n",
      "          Dropout-14                 [-1, 2304]               0\n",
      "           Linear-15                 [-1, 1024]       2,360,320\n",
      "             ReLU-16                 [-1, 1024]               0\n",
      "          Dropout-17                 [-1, 1024]               0\n",
      "           Linear-18                  [-1, 512]         524,800\n",
      "             ReLU-19                  [-1, 512]               0\n",
      "           Linear-20                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 4,617,546\n",
      "Trainable params: 4,617,546\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.46\n",
      "Params size (MB): 17.61\n",
      "Estimated Total Size (MB): 20.08\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b917ae3-c2ed-41cf-bb5b-87a7dfb65e29",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbe1730-fb1b-4885-a488-593b386b828d",
   "metadata": {},
   "source": [
    "##### 💡 **손실 함수 및 최적화 방법 정의하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dbd9d7-ec3c-4b40-9e4f-7afbafd9b998",
   "metadata": {},
   "source": [
    "- 다중 분류 문제에서는 Cross Entropy Loss를 기본으로 사용\n",
    "    - 파이토치에서 제공하는 Cross Entropy Loss는 Softmax 계산까지 포함\n",
    "    - 모델의 마지막 출력값에 별도의 softmax 적용을 하지 않아도 된다. \n",
    "- **GPU 연산을 위해 모델을 불러올 때 .to(device) 반드시 붙여주기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4711237d-8da8-48a2-8103-6ddf04b3443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "alexnet = AlexNet().to(device)\n",
    "optimizer = optim.Adam(alexnet.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ef3820-3e36-4e12-952b-0fdb09b38549",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8a9499-0c80-4b9e-98fb-c7299e11497b",
   "metadata": {},
   "source": [
    "##### 💡 **AlexNet 모델 학습하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f4f6b1-8c86-42d5-ba4f-12f46b931ea4",
   "metadata": {},
   "source": [
    "- **GPU 연산을 위해 데이터에도 .to(device) 붙여주기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260ef8e-46c6-4bc0-8b5c-a5f3b17cc27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프를 그리기 위한 loss 저장용 리스트\n",
    "loss_ = []\n",
    "\n",
    "# 배치개수\n",
    "n = len(trainloader)\n",
    "\n",
    "for epoch in range(50) :\n",
    "    running_loss = 0.0\n",
    "    for data in trainloader :\n",
    "        # 원래는 inputs, labels = data로 하는데 각각 device 붙여주기 위해 인덱스로 따로 뗌\n",
    "        # 배치 데이터\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 예측값 산출\n",
    "        outputs = alexnet(inputs)\n",
    "        \n",
    "        # 손실함수 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 손실 함수 기준으로 역전파 선언\n",
    "        loss.backward()\n",
    "        \n",
    "        # 가중치 최적화\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    loss_.append(running_loss/n)\n",
    "    print('[%d] loss: %.3f' % (epoch+1, running_loss/len(trainloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74489a-25ec-42a7-88e4-5b1bb96fe843",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5507bc-c86a-4b99-beb0-36da3780059d",
   "metadata": {},
   "source": [
    "##### 💡 **학습 손실 함수 그래프 그리기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d21f7de-5e28-4460-ac20-e9fa17c967d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76828d30-b226-4c21-867d-2c1b7ad01763",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02cfd20-1729-49a3-a957-7c6cb89ac5d4",
   "metadata": {},
   "source": [
    "##### 💡 **파이토치 모델 저장 및 불러오기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c12438-0eef-4eec-9590-ce7fa235318b",
   "metadata": {},
   "source": [
    "- 평가가 잘 되었다면 추후 이어서 학습을 하거나 실험 자료를 남기기 위해 모델을 저장해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bfe19bb-16f9-48cf-8613-bd2392d4d9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 경로와 모델평.pth 입력\n",
    "PATH = './model/cifal_alexnet.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a70d1e87-ceca-479e-a987-d9cc5d5ecc20",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './model/cifal_alexnet.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 모델 저장\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43malexnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/serialization.py:376\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03mSaves an object to a disk file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m _check_dill_version(pickle_module)\n\u001b[0;32m--> 376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './model/cifal_alexnet.pth'"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "torch.save(alexnet.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c32589c-401b-451c-a459-4573661fa255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장은 모델을 통째로 저장하는 것이 아니고 모델 파라미터를 저장\n",
    "# 따라서 저장된 모델을 불러올 때 모델이 선행적으로 선언되어 있어야만 한다.\n",
    "alexnet = AlexNet().to(device)\n",
    "\n",
    "# 모델의 파라미터를 불러와 모델에 주입\n",
    "alexnet.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3efbac-4ff6-483e-959e-854504915146",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64609752-2057-443c-bd2d-bcf5ad1b406f",
   "metadata": {},
   "source": [
    "##### 💡 **평가하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d880a-a3e1-4c9a-b7e5-20fed4da6303",
   "metadata": {},
   "source": [
    "- `_, predicted = torch.max(outputs, 1)`\n",
    "    - outputs은 크기가 (배치 크기) x 10인 벡터 형태로 나온다. \n",
    "    - 따라서 열 기준으로 가장 큰 원소의 위치가 라벨이 되는 것이기 때문에 최댓값을 열(1) 기주으로 계산하여 예측값을 구한다.\n",
    "    - `torch.max`는 최댓값, 최댓값의 위치를 산출 (최댓값은 필요 없으므로 _로 처리하여 해당 출력값은 저장 X)\n",
    "    - 즉, _, predicted는 최댓값의 위치만 predicted에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9babcf89-886b-44a6-b203-63b52907bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 개수\n",
    "correct = 0\n",
    "\n",
    "# 전체 개수\n",
    "total = 0\n",
    "\n",
    "# 평가 시에는 requires_grad 비활성화\n",
    "with torch.no_grad() :\n",
    "    # 평가 시에는 드롭아웃 등과 같은 정규화 작업 X (비활성화)\n",
    "    alexnet.eval()\n",
    "    for data in testloader :\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = alexnet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print('Test accuracy: %.2f %%' %(100*correct/total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
